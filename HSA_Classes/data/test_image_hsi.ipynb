{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61335015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "path = \"../\"\n",
    "sys.path.append(path)\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from PIL import Image\n",
    "from loguru import logger\n",
    "import Model as hsa_model\n",
    "import DataSet as hsa_dataset\n",
    "import Viz as hsa_viz\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sink=f\"HSA_log.log\", level=\"CRITICAL\")\n",
    "import MultiFilter as hsa_multifilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1828202",
   "metadata": {},
   "source": [
    "Read Images and plot shape of np.array associated with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"./night_sky2.jpeg\"\n",
    "img = Image.open(image_path)\n",
    "array = np.array(img)\n",
    "print(f\"array shape: {array.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968485f2",
   "metadata": {},
   "source": [
    "Plot images of the RGB spectra and original data as np before conversion to df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a622cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "titles = [\"Red Spectra\", \"Blue Spectra\", \"Green Spectra\", \"Original Image\"]\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    try:\n",
    "        sns.heatmap(\n",
    "            array[:, :, i],\n",
    "            square=True,\n",
    "            xticklabels=False,\n",
    "            yticklabels=False,\n",
    "            cbar=False,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_title(titles[i])\n",
    "    except:\n",
    "        ax.set_title(titles[i])\n",
    "        image = mpimg.imread(image_path)\n",
    "        ax.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbf6174",
   "metadata": {},
   "source": [
    "Generate a list of data points from image and convert to df to begin vanilla preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None\n",
    "columns = [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "for row in range(len(array)):\n",
    "    try:\n",
    "        data = np.append(data, array[row, :, :], axis=0)\n",
    "    except:\n",
    "        data = array[row, :, :]\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(data)\n",
    "preprocessed_df = pd.DataFrame(scaler.transform(data), columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3229b7ea",
   "metadata": {},
   "source": [
    "Instantiate the model and dataloader with preprocessed data as a np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c8a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_std_tolerance = 1.2\n",
    "penalty_ratio = 0.99\n",
    "cutoff_distance = 1\n",
    "converge_toll=1e-5,\n",
    "\n",
    "model = hsa_model.HSA_model(\n",
    "    penalty_ratio = penalty_ratio,\n",
    "    cutoff_distance = cutoff_distance,\n",
    "    converge_toll = converge_toll,\n",
    "    anomaly_std_tolerance = anomaly_std_tolerance,\n",
    "    logger=logger,\n",
    "    affinity_matrix_iterations = 20,\n",
    "    lr = 2.7,\n",
    "    multifilter_flag = 0,\n",
    ")\n",
    "dataset = hsa_dataset.HSA_dataset(\n",
    "    preprocessed_np=preprocessed_df.to_numpy(), logger=logger\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = \"Images/\"\n",
    "log_directory = f\"{base_directory}/logs/\"\n",
    "results_directory = f\"{base_directory}/results/\"\n",
    "model.set_directories(log_directory, results_directory)\n",
    "\n",
    "model.preprocessed_df = preprocessed_df\n",
    "\n",
    "logger.info(\"Starting to run through the dataloader on initial pass.\")\n",
    "unique_id_str = \"test\"\n",
    "batch_size = 1000\n",
    "iterations = 10000\n",
    "\n",
    "for i, data in enumerate(dataloader):  # setting up gpus\n",
    "    model.set_trial(i * batch_size, batch_size, unique_id_str)\n",
    "\n",
    "    # Model set up and weight generation\n",
    "    model.read_data(\n",
    "        data_multifilter_df=data.squeeze(0)\n",
    "    ).vertex_weights_distances().weight_generation().graph_evolution()\n",
    "\n",
    "    model.train(iterations=iterations)\n",
    "    model.infer(preprocessed_df)\n",
    "\n",
    "    # Store anomalous predictions throughout all batches for use in multi filter\n",
    "    try:\n",
    "        total_anomaly_index = np.append(total_anomaly_index, model.anomaly_index_raw)\n",
    "    except:\n",
    "        print(i)\n",
    "        total_anomaly_index = model.anomaly_index_raw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e54bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataloader)*batch_size)\n",
    "print(len(preprocessed_df))\n",
    "i*batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c946df",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_index, mix_data, anomaly_index = model.global_collect_multifilter_df(\n",
    "    preprocessed_df.to_numpy(),\n",
    "    total_anomaly_index[: len(preprocessed_df.to_numpy())].astype(int),\n",
    "    mf_batch_size=9 * len(total_anomaly_index),\n",
    ")\n",
    "anomaly_prediction_frequency_df = model.apf_df_generation(anomaly_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b05c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.uni_shuffle_multifilter_df(\n",
    "    mix_index.astype(int), mix_data.astype(int), anomaly_index.astype(int)\n",
    ")\n",
    "mf_data = model.all_data\n",
    "logger.debug(\"Anomalous data has been colleted into first multifilter dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6eedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Original data input- preprocessed_df: {preprocessed_df.shape} \\nFirst rank anomlus predictions- anomaly_prediction_frequency_df:{anomaly_prediction_frequency_df.shape} \\nMultifilter data shape- mf_data: {mf_data.shape}, {type(mf_data)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02683b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c29f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_filters = 30\n",
    "all_index_user = model.all_index_user\n",
    "MF_model, anomaly_prediction_frequency_df = hsa_multifilter.multifilter(\n",
    "    multi_filters,\n",
    "    batch_size,\n",
    "    penalty_ratio,\n",
    "    cutoff_distance,\n",
    "    anomaly_std_tolerance,\n",
    "    mf_data,\n",
    "    all_index_user,\n",
    "    model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023cd19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = hsa_viz.HSA_viz(\n",
    "    MF_model.m,\n",
    "    MF_model.preprocessed_np,\n",
    "    batch_size,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    0,\n",
    "    \"plot_directory\",\n",
    "    \"unique_id_str\",\n",
    "    logger,\n",
    ")\n",
    "viz.heatmap_bin_predictions_vert(\n",
    "    MF_model.bin_score,\n",
    "    MF_model.anomalous_location,\n",
    "    MF_model.anomaly_index_raw,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdd8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df[\"Anomaly Bin Count\"] = np.zeros(len(preprocessed_df))\n",
    "for i in anomaly_prediction_frequency_df[\n",
    "    anomaly_prediction_frequency_df[\"Anomaly Bin Count\"] > 0\n",
    "].index:\n",
    "    preprocessed_df.loc[anomaly_prediction_frequency_df.loc[i], \"Anomaly Bin Count\"] = (\n",
    "        anomaly_prediction_frequency_df.loc[i, \"Anomaly Bin Count\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3faf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 1280\n",
    "anomaly_score_np = []\n",
    "for i in range(int(len(preprocessed_df) / image_width)):\n",
    "    anomaly_score_np.append(\n",
    "        preprocessed_df[\"Anomaly Bin Count\"][i * image_width : (1 + i) * image_width]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "titles = [\"Red Spectra\", \"Blue Spectra\", \"Green Spectra\", \"Anomaly Scores\"]\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    try:\n",
    "        sns.heatmap(\n",
    "            array[:, :, i],\n",
    "            square=True,\n",
    "            xticklabels=False,\n",
    "            yticklabels=False,\n",
    "            cbar=False,\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_title(titles[i])\n",
    "    except:\n",
    "        ax.set_title(titles[i])\n",
    "        sns.heatmap(\n",
    "            anomaly_score_np,\n",
    "            square=True,\n",
    "            xticklabels=False,\n",
    "            yticklabels=False,\n",
    "            cbar=False,\n",
    "            ax=ax,\n",
    "            cmap=\"rocket_r\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004fb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Max anomaly score: {np.array(anomaly_score_np).max()}\")\n",
    "print(f\"Number of Anomalies:  {np.sum(np.greater(np.array(anomaly_score_np), 0))}\")\n",
    "sns.histplot(\n",
    "    preprocessed_df.loc[preprocessed_df[\"Anomaly Bin Count\"] > 0][\"Anomaly Bin Count\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251b784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc4d35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HSA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
